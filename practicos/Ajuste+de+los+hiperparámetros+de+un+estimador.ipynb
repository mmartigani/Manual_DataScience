{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#¿Qué-son-los-hiperparámetros?\" data-toc-modified-id=\"¿Qué-son-los-hiperparámetros?-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>¿Qué son los hiperparámetros?</a></span></li><li><span><a href=\"#¿Se-pueden-optimizar-los-hiperparámetros?\" data-toc-modified-id=\"¿Se-pueden-optimizar-los-hiperparámetros?-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>¿Se pueden optimizar los hiperparámetros?</a></span></li><li><span><a href=\"#¿Qué-hace-falta-para-llevar-a-cabo-una-búsqueda-de-hiperparámetros?\" data-toc-modified-id=\"¿Qué-hace-falta-para-llevar-a-cabo-una-búsqueda-de-hiperparámetros?-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>¿Qué hace falta para llevar a cabo una búsqueda de hiperparámetros?</a></span></li><li><span><a href=\"#Métodos-de-búsqueda-de-hiperparámetros\" data-toc-modified-id=\"Métodos-de-búsqueda-de-hiperparámetros-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Métodos de búsqueda de hiperparámetros</a></span><ul class=\"toc-item\"><li><span><a href=\"#GridSearchCV-(búsqueda-exhaustiva-de-cuadrícula)\" data-toc-modified-id=\"GridSearchCV-(búsqueda-exhaustiva-de-cuadrícula)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>GridSearchCV (búsqueda exhaustiva de cuadrícula)</a></span><ul class=\"toc-item\"><li><span><a href=\"#¿Cómo-se-usa-GridSearchCV-en-Scikit-Learn?\" data-toc-modified-id=\"¿Cómo-se-usa-GridSearchCV-en-Scikit-Learn?-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>¿Cómo se usa GridSearchCV en Scikit-Learn?</a></span></li><li><span><a href=\"#Ejemplo-práctico\" data-toc-modified-id=\"Ejemplo-práctico-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Ejemplo práctico</a></span></li></ul></li><li><span><a href=\"#RandomizedSearchCV-(búsqueda-aleatoria)\" data-toc-modified-id=\"RandomizedSearchCV-(búsqueda-aleatoria)-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>RandomizedSearchCV (búsqueda aleatoria)</a></span></li></ul></li><li><span><a href=\"#Ampliación\" data-toc-modified-id=\"Ampliación-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Ampliación</a></span><ul class=\"toc-item\"><li><span><a href=\"#Especificar-una-métrica-objetiva\" data-toc-modified-id=\"Especificar-una-métrica-objetiva-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Especificar una métrica objetiva</a></span></li><li><span><a href=\"#Especificar-múltiples-métricas-para-evaluación\" data-toc-modified-id=\"Especificar-múltiples-métricas-para-evaluación-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Especificar múltiples métricas para evaluación</a></span></li><li><span><a href=\"#Selección-de-modelos\" data-toc-modified-id=\"Selección-de-modelos-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Selección de modelos</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué son los hiperparámetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En scikit-learn, se pasan como argumentos al constructor de las clases. Hiperparámetros típicos son, por ejemplo, \"C\", \"kernel\" y \"gamma\" para los clasificadores de vectores de soporte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Se pueden optimizar los hiperparámetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es posible y recomendable buscar en el espacio de hiperparámetros los mejores valores para, a su vez, obtener la mejor puntuación de validación cruzada. Cualquier parámetro proporcionado al construir un estimador puede optimizarse de esta manera. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué hace falta para llevar a cabo una búsqueda de hiperparámetros?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una búsqueda consta de:\n",
    "\n",
    "- Un estimador (un objeto regresor o clasificador, como por ejemplo sklearn.svm.SVC())\n",
    "- Un espacio de parámetros en el cual buscar\n",
    "- Un método para buscar o muestrear candidatos\n",
    "- Un esquema de validación cruzada\n",
    "- Una función de puntuación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos de búsqueda de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Scikit-Learn se proporcionan dos enfoques genéricos para buscar hiperparámetros: \n",
    "\n",
    "- Para un conjunto de valores dados, **GridSearchCV** considera exhaustivamente todas las combinaciones posibles de dichos valores de hiperparámetros.\n",
    "- El método **RandomizedSearchCV** puede analizar un número determinado de valores de un espacio de hiperparámetros con una distribución específica. \n",
    "\n",
    "Es importante tener en cuenta que puede haber unos pocos hiperparámetros que tengan un gran impacto en el rendimiento del modelo, mientras que otros quizás puedan dejarse simplemente con los valores que les da Scikit-Learn por defecto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV (búsqueda exhaustiva de cuadrícula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda de cuadrícula (*GridSearchCV* en Scikit-Learn) estudia todas las posibles combinaciones de valores de hiperparámetros, que se especifican mediante el parámetro param_grid, como por ejemplo de la siguiente manera:\n",
    "\n",
    "param_grid = [\n",
    "\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  \n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "  \n",
    " ]\n",
    " \n",
    "Este ejemplo de param_grid indica que se deben explorar dos cuadrículas: una con un kernel lineal y valores C en [1, 10, 100, 1000], y la segunda con un kernel RBF, y el producto cruzado de los valores C en [1, 10 , 100, 1000] y valores gamma en [0.001, 0.0001].\n",
    "\n",
    "Tras evaluar todas las combinaciones, se conserva la mejor de ellas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo se usa GridSearchCV en Scikit-Learn?\n",
    "\n",
    "class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "\n",
    "Veamos los hiperparámetros más importantes de esta clase:\n",
    "- *estimator*: un estimador Scikit-Learn, como por ejemplo *sklearn.svm.SVC()*.\n",
    "- *param_grid*: diccionario o lista de diccionarios. Debe proporcionar los nombres de los hiperparámetros con los valores que se desean probar. \n",
    "- *scoring*: métrica/s para evaluar las predicciones en el conjunto de prueba. Si es *None*, se utiliza la métrica de puntuación que tenga asociada el estimador.\n",
    "- *refit*: indica si se desea reajustar el estimador utilizando los mejores parámetros encontrados en todo el conjunto de datos. Ese estimador reajustado estará disponible en el atributo *best_estimator_* y se podrá utilizar para hacer predicciones directamente con la instancia de GridSearchCV.\n",
    "- *cv*: determina la estrategia de división de validación cruzada. Consultar las posibles entradas para cv en la documentación oficial.\n",
    "- *verbose*: controla la verbosidad (información que se muestra durante la ejecución). Se indica mediante un número entero, y cuanto más alto sea su valor, más mensajes se mostrarán.\n",
    "- *error_score*: valor para asignar a la puntuación si se produce un error en el ajuste del estimador. \n",
    "- *return_train_score*: si es *False*, el atributo *cv_results_* no incluirá las puntuaciones de entrenamiento. El cálculo de puntuaciones de entrenamiento se usa para obtener información sobre cómo diferentes configuraciones de parámetros impactan en la compensación de overfitting/underfitting. Sin embargo, calcular los resultados de las métricas de evaluación en el conjunto de entrenamiento puede ser computacionalmente costoso y no es estrictamente necesario para seleccionar los parámetros que producen el mejor rendimiento de generalización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo práctico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\user\\\\anaconda3\\\\envs\\\\python-385\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramgrid = {\"kernel\": (\"linear\", \"rbf\"),\n",
    "            \"C\": [1, 10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator = svc, \n",
    "                   param_grid = paramgrid, \n",
    "                   scoring=None, \n",
    "                   cv=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0020</td>\n",
       "      <td>1.784161e-07</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>1</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0024</td>\n",
       "      <td>7.999420e-04</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>1</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 1, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.021082</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>4.000187e-04</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>10</td>\n",
       "      <td>linear</td>\n",
       "      <td>{'C': 10, 'kernel': 'linear'}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.038873</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 10, 'kernel': 'rbf'}</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.016330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0         0.0020  1.784161e-07           0.0018        0.001600       1   \n",
       "1         0.0024  7.999420e-04           0.0010        0.000632       1   \n",
       "2         0.0008  4.000187e-04           0.0006        0.000490      10   \n",
       "3         0.0010  0.000000e+00           0.0000        0.000000      10   \n",
       "\n",
       "  param_kernel                         params  split0_test_score  \\\n",
       "0       linear   {'C': 1, 'kernel': 'linear'}           0.966667   \n",
       "1          rbf      {'C': 1, 'kernel': 'rbf'}           0.966667   \n",
       "2       linear  {'C': 10, 'kernel': 'linear'}           1.000000   \n",
       "3          rbf     {'C': 10, 'kernel': 'rbf'}           0.966667   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           1.000000           0.966667           0.966667                1.0   \n",
       "1           0.966667           0.966667           0.933333                1.0   \n",
       "2           1.000000           0.900000           0.966667                1.0   \n",
       "3           1.000000           0.966667           0.966667                1.0   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.980000        0.016330                1  \n",
       "1         0.966667        0.021082                4  \n",
       "2         0.973333        0.038873                3  \n",
       "3         0.980000        0.016330                1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, kernel='linear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'kernel': 'linear'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics._scorer._passthrough_scorer(estimator, *args, **kwargs)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.n_splits_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV (búsqueda aleatoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien la búsqueda de cuadrícula es el método actualmente más utilizado para la optimización de parámetros, otras técnicas tienen propiedades que también las convierten en buenas opciones. *RandomizedSearchCV* implementa una búsqueda aleatoria de parámetros, donde cada configuración se muestrea a partir de una distribución de posibles valores de parámetros. Esto tiene dos ventajas principales sobre una búsqueda exhaustiva:\n",
    "\n",
    "- Se puede elegir un presupuesto independientemente del número de parámetros y valores posibles.\n",
    "- Agregar parámetros que no influyen en el rendimiento no disminuye la eficiencia.\n",
    "\n",
    "La especificación de cómo se deben muestrear los parámetros se realiza mediante un diccionario, muy similar a la especificación de parámetros para GridSearchCV. Además, un presupuesto de cálculo, que es el número de candidatos muestreados o iteraciones de muestreo, se especifica mediante el parámetro \"n_iter\". Para cada parámetro, se puede especificar una distribución sobre los valores posibles o una lista de opciones discretas (que se muestrearán de manera uniforme):\n",
    "\n",
    "{'C': scipy.stats.expon(scale=100), 'gamma': scipy.stats.expon(scale=.1),\n",
    "\n",
    "  'kernel': ['rbf'], 'class_weight':['balanced', None]}\n",
    "  \n",
    "Este ejemplo utiliza el módulo scipy.stats, que contiene muchas distribuciones útiles para los parámetros de muestreo, tales como *expon*, *gamma*, *uniform* o *randint*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ampliación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificar una métrica objetiva \n",
    "\n",
    "**De forma predeterminada, la búsqueda de parámetros utiliza la función *score* del estimador** para evaluar la configuración de un parámetro, concretamente sklearn.metrics.accuracy_score para clasificación y sklearn.metrics.r2_score para regresión. Para algunas aplicaciones, otras funciones de puntuación son más adecuadas (por ejemplo, en la clasificación no balanceada, la puntuación de precisión no suele ser informativa). Se puede especificar una función de puntuación alternativa a través del  parámetro \"scoring\" de GridSearchCV, RandomizedSearchCV y muchas de las herramientas de validación cruzada. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Especificar múltiples métricas para evaluación\n",
    "\n",
    "GridSearchCV y RandomizedSearchCV permiten especificar varias métricas para el parámetro \"scoring\".\n",
    "\n",
    "La puntuación multimétrica puede especificarse de dos maneras:\n",
    "- Como una lista de cadenas de nombres de puntuaciones.\n",
    "\n",
    "scoring = ['accuracy', 'precision']\n",
    "\n",
    "- Como un diccionario que correlaciona el nombre de la puntuación con la función que permite calcular dicha puntuación. \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scoring = {'accuracy': make_scorer(accuracy_score),\n",
    "           'prec': 'precision'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de modelos\n",
    "A menudo, se utilizan los métodos de evaluación de hiperparámetros anteriores para comparar el rendimiento de diferentes modelos entre sí, o de diferentes versiones de un mismo modelo. \n",
    "\n",
    "Al evaluar cada modelo resultante, es importante hacerlo con datos que no se hayan \"visto\" durante el proceso de búsqueda de la cuadrícula, es decir, se recomienda dividir los datos en un conjunto de desarrollo (que será el que utilice el método GridSearchCV) y un conjunto de evaluación para calcular métricas de rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
